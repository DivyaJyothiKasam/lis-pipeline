#!/usr/bin/env groovy

def RunPowershellCommand(psCmd) {
    bat "powershell.exe -NonInteractive -ExecutionPolicy Bypass -Command \"[Console]::OutputEncoding=[System.Text.Encoding]::UTF8;$psCmd;EXIT \$global:LastExitCode\""
}

def GetTestResults(type) {
    withEnv(["Type=${type}"]) {
        def returnValues = powershell returnStdout: true, script: '''
            $file = Get-Item ".\\Report\\*-junit.xml" -ErrorAction SilentlyContinue | Sort-Object LastWriteTimeUtc | select -Last 1
            if (!$file) {
                return 0
            }
            $content = [xml](Get-Content $file)
            $failCase = [int]($content.testsuites.testsuite.failures)
            $allCase = [int]($content.testsuites.testsuite.tests)
            $abortCase = [int]($content.testsuites.testsuite.errors)
            $skippedCase = [int]($content.testsuites.testsuite.skipped)
            $passCase = $allCase - $failCase - $abortCase - $skippedCase

            if ($env:Type -eq "pass") {
                return $passCase
            } elseif ($env:Type -eq "abort") {
                return $abortCase
            } elseif ($env:Type -eq "fail") {
                return $failCase
            } elseif ($env:Type -eq "skipped") {
                return $skippedCase
            } elseif ($env:Type -eq "all") {
                return $allCase
            }
        '''
        return "${returnValues}"
    }
}

def reportPipelineStatus(status) {
    println "Pipeline report for status: ${status}"

    env.COMPOSITE_KEYS = "PipelineName,PipelineBuildNumber"
    withCredentials(bindings: [file(credentialsId: 'KERNEL_PIPELINE_EXECUTION_DB_CREDS',
        variable: 'KERNEL_PIPELINE_EXECUTION_DB_CREDS')]) {
        dir('ker_pi_rep' + env.BUILD_NUMBER + env.BRANCH_NAME) {
            sh '''#!/bin/bash
                cat << EOF > "${WORKSPACE}/scripts/reporting/db_rows_${BRANCH_NAME}_${BUILD_NUMBER}.json"
[{  "StartDate": "${START_DATE}",
    "EndDate": "${END_DATE}",
    "PipelineName": "${JOB_NAME}",
    "PipelineBuildNumber": ${BUILD_NUMBER},
    "PipelineBuildUrl": "${BUILD_URL}",
    "KernelVersion": "${KERNEL_VERSION}",
    "KernelType": "${KERNEL_TYPE}",
    "SignedOffBy": "${SIGNED_OFF_BY}",
    "SignedOffResult": "${SIGNED_OFF_RESULT}",
    "DistroVersion": "${Distro}"  }]
EOF
                python "${WORKSPACE}/scripts/reporting/report_pipeline_stage_status.py" \
                --db_rows "${WORKSPACE}/scripts/reporting/db_rows_${BRANCH_NAME}_${BUILD_NUMBER}.json" \
                --composite_keys "${COMPOSITE_KEYS}" \
                --db_config "${KERNEL_PIPELINE_EXECUTION_DB_CREDS}"
            '''
        }
    }
}

def reportStageStatus(stageInfo, useTestResults) {
    env.stageName = stageInfo["Name"]
    env.currentPlatform = stageInfo["Platform"]
    env.startDate = stageInfo["StartDate"]
    env.endDate = stageInfo["EndDate"]

    env.passCount = ''
    env.abortCount = ''
    env.failCount = ''
    env.skippedCount = ''
    if (useTestResults) {
        env.passCount = GetTestResults("pass").trim()
        env.abortCount = GetTestResults("abort").trim()
        env.failCount = GetTestResults("fail").trim()
        env.skippedCount = GetTestResults("skipped").trim()
    }

    env.MASTER_COMPOSITE_KEYS = "PipelineName,PipelineBuildNumber"
    env.COMPOSITE_KEYS = "StageName"
    env.FOREIGN_KEY = "PipelineExecutionId"
    stage ("report_stage") {
        node ("meta_slave") {

            withCredentials(bindings: [file(credentialsId: 'KERNEL_PIPELINE_EXECUTION_STAGE_DB_CREDS',
                variable: 'KERNEL_PIPELINE_EXECUTION_STAGE_DB_CREDS')]) {
                checkout scm
                sh '''#!/bin/bash
        cat << EOF > "${WORKSPACE}/scripts/reporting/db_rows${stageName}${BUILD_NUMBER}${BRANCH_NAME}.json"
[{  "StageName": "${stageName}",
"StartDate": "${startDate}",
"EndDate": "${endDate}",
"TestsPassed": "${passCount}",
"TestsAborted": "${abortCount}",
"TestsFailed": "${failCount}",
"TestsSkipped": "${skippedCount}",
"PipelineName": "${JOB_NAME}",
"PipelineBuildNumber": ${BUILD_NUMBER},
"Platform": "${currentPlatform}"  }]
EOF
            python "${WORKSPACE}/scripts/reporting/report_pipeline_stage_status.py" \
                --db_rows "${WORKSPACE}/scripts/reporting/db_rows${stageName}${BUILD_NUMBER}${BRANCH_NAME}.json" \
                --composite_keys "${COMPOSITE_KEYS}" \
                --foreign_key "${FOREIGN_KEY}" \
                --master_composite_keys "${MASTER_COMPOSITE_KEYS}" \
                --db_config "${KERNEL_PIPELINE_EXECUTION_STAGE_DB_CREDS}"
            '''
            }
        }
    }
}

properties ([
    overrideIndexTriggers(false),
    parameters([
        choice (name: 'Distro', choices: 'trusty\nxenial\nbionic\ncosmic\ndisco',
                description: 'trusty - 14.04 validation <br> xenial - 16.04 validation <br> bionic - 18.04 validation <br> cosmic - 18.10 validation <br> disco - 19.04 validation'),
        choice (name: 'KernelType', choices: 'linux-azure\nlinux-azure-edge',
                description: 'linux-azure - latest proposed linux-azure kernel validation <br> linux-azure-edge - latest proposed linux-azure-edge kernel validation'),
        string(name: 'KernelVersion', defaultValue: "", description: 'The exact kernel version to be tested. Example: 5.0.0.1010.9. If left empty, the version will not be present in the database reports.'),
        choice (name: 'Platform', choices: 'azure\nhyperv\nall',
                description: 'azure - only Azure validation <br> all - all platforms validation <br> hyperv - only Hyper-V validation'),
        choice (name: 'Performance', choices: 'yes\nno',
                description: 'yes - will do Azure Performance testing <br> no - Azure Performance testing will be skipped'),
        choice (name: 'sendMail', choices: 'no\nyes',
                description: 'no - will not send mail <br> yes - will send mail')
    ])
])

def ARM_DISTRO_HASH = [trusty:'Canonical UbuntuServer 14.04.5-LTS latest',
                  xenial:'Canonical UbuntuServer 16.04-LTS latest',
                  bionic:'Canonical UbuntuServer 18.04-LTS latest',
                  cosmic:'Canonical UbuntuServer 18.10 latest',
                  disco:'Canonical UbuntuServer 19.04 latest']
def HYPERV_VHD_HASH = [trusty:'Ubuntu_14.04.5\\Ubuntu14.04.5-server.vhdx',
                  xenial:'ubuntu_16.04.5\\ubuntu_16.04.5.vhdx',
                  bionic:'ubuntu_18.04.1\\ubuntu_18.04.1_gen1_gen2.vhdx',
                  cosmic:'ubuntu_18.10\\ubuntu_18.10_gen1_gen2.vhdx',
                  disco: 'ubuntu_19.04\\ubuntu_19.04_gen1_gen2.vhdx']

def HYPERV_VALIDATION_TESTS_HASH = [HV_P0_VALIDATION:"-TestPriority 0 -ExcludeTests 'LIVE-MIGRATE-QUICK-MIGRATE,NVME-DISK-VALIDATION,SRIOV-VERIFY-LSPCI,SRIOV-VERIFY-SINGLE-VF-CONNECTION,LIVE-MIGRATE,NVME-FSTRIM,NVME-BLKDISCARD'",
    HV_P1_VALIDATION:"-TestPriority 1 -ExcludeTests 'LIVE-MIGRATE-FAILOVER,DYNAMIC-MEMORY-HIGH-PRIORITY,SRIOV-DISABLE-ENABLE-PCI,SRIOV-VERIFY-SINGLE-VF-CONNECTION-ONE-VCPU,SRIOV-VERIFY-SINGLE-VF-CONNECTION-MAX-VCPU,SRIOV-VERIFY-MAX-VF-CONNECTION,SRIOV-VERIFY-MAX-VF-CONNECTION-MAX-VCPU,SRIOV-ADD-MAX-NICS-DURING-PROVISION,SRIOV-INTERRUPTS-CHANGE,SRIOV-DISABLEVF-ON-GUEST,SRIOV-RELOAD-MODULE,SRIOV-DISABLEVF-PING,SRIOV-DISABLEVF-IPERF,SRIOV-DETACH-NIC,SRIOV-DISABLEVF-ONHOST,SRIOV-DISABLE-NIC,SRIOV-DISABLE-VMQ,SRIOV-CHANGE-RSS,SRIOV-MEASURE-VF-FAILBACK,SRIOV-MULTICAST,SRIOV-BROADCAST,SRIOV-REBOOT-VM,SRIOV-STRESS-SAVE,SRIOV-STRESS-PAUSE,PERF-NETWORK-TCP-LATENCY-SRIOV,PERF-NETWORK-TCP-SINGLE-CONNECTION-THROUGHPUT-SRIOV,PERF-NVME-4K-IO,PERF-NETWORK-TCP-SINGLE-CONNECTION-THROUGHPUT-SYNTHETIC,NVME-DISK-OPERATIONS,NVME-CHECK-EXPECTED-FAILURES,NVME-PCI-RESCIND,PERF-NETWORK-TCP-LATENCY-Synthetic,PERF-STORAGE-4K-IO'",
    HV_SRIOV_VALIDATION:"-TestCategory 'Functional' -TestArea 'SRIOV' -ExcludeTests 'SRIOV-MOVE-VHD'"]

def AZURE_VALIDATION_TESTS_HASH = [AZURE_P0_VALIDATION:"-TestPriority 0 -ExcludeTests 'NVME-DISK-VALIDATION,NVME-FSTRIM,NVME-BLKDISCARD,VERIFY-DPDK-COMPLIANCE'",
    AZURE_P1_VALIDATION:"-TestPriority 1 -ExcludeTests 'PERF-NETWORK-TCP-THROUGHPUT-MULTICLIENTS-NTTTCP-Synthetic,PERF-NETWORK-TCP-THROUGHPUT-MULTICLIENTS-NTTTCP-SRIOV,PERF-NETWORK-TCP-LATENCY-Synthetic,PERF-NETWORK-TCP-LATENCY-SRIOV,PERF-STORAGE-4K-IO,PERF-STORAGE-1024K-IO,PERF-NETWORK-TCP-SINGLE-CONNECTION-THROUGHPUT-SYNTHETIC,PERF-NETWORK-TCP-SINGLE-CONNECTION-THROUGHPUT-SRIOV,PERF-SYSCALL-BENCHMARK,PERF-NVME-4K-IO,NVME-MAX-DISK-VALIDATION,NVME-DISK-OPERATIONS,NVME-CHECK-EXPECTED-FAILURES,NVME-FILE-SYSTEM-VERIFICATION-GENERIC,NVME-PCI-RESCIND'",
    AZURE_P2_VALIDATION:"-TestPriority 2 -ExcludeTests 'PERF-NETWORK-TCP-THROUGHPUT-MULTICONNECTION-NTTTCP-Synthetic,PERF-NETWORK-TCP-THROUGHPUT-MULTICONNECTION-NTTTCP-SRIOV,PERF-NETWORK-UDP-1K-THROUGHPUT-MULTICONNECTION-NTTTCP-Synthetic,PERF-NETWORK-UDP-1K-THROUGHPUT-MULTICONNECTION-NTTTCP-SRIOV,PERF-NETWORK-UDP-1K-THROUGHPUT-MULTICLIENTS-NTTTCP-Synthetic,PERF-NETWORK-UDP-1K-THROUGHPUT-MULTICLIENTS-NTTTCP-SRIOV,PERF-NETWORK-UDP-THROUGHPUT-MULTICONNECTION-Synthetic,PERF-NETWORK-UDP-THROUGHPUT-MULTICONNECTION-SRIOV,PERF-STORAGE-OVER-NFS-Synthetic-TCP-4K,PERF-STORAGE-OVER-NFS-Synthetic-UDP-4K,PERF-STORAGE-OVER-NFS-SRIOV-TCP-4K,PERF-STORAGE-OVER-NFS-SRIOV-UDP-4K,PERF-NETWORK-TCP-NETPERF-SINGLE-PPS-Synthetic,PERF-NETWORK-TCP-NETPERF-SINGLE-PPS-SRIOV,PERF-NETWORK-TCP-NETPERF-MAX-PPS-Synthetic,PERF-NETWORK-TCP-NETPERF-MAX-PPS-SRIOV,PERF-GOLANG-BENCHMARK,NVME-FILE-SYSTEM-VERIFICATION-XFS,NVME-FILE-SYSTEM-VERIFICATION-EXT4,NVME-FILE-SYSTEM-VERIFICATION-BTRFS,AZURE-WINDOWS-NESTED-HYPERV-STORAGE-MULTIDISK,AZURE-NESTED-HYPERV-NTTTCP-DIFFERENT-L1-NAT,AZURE-WINDOWS-NESTED-HYPERV-STORAGE-SINGLE-DISK,VERIFY-DPDK-NFF-GO,PERF-DPDK-SINGLE-CORE-PPS-DS4,VERIFY-DPDK-OVS,PERF-DPDK-SINGLE-CORE-PPS-DS15,PERF-DPDK-FWD-PPS-DS15,PERF-DPDK-MULTICORE-PPS-F32'",
    AZURE_NVME_VALIDATION:"-TestCategory 'Functional' -TestArea 'NVME'"]

def AZURE_PERFORMANCE_TESTS_HASH = [PERF_NTTTCP:"-TestNames 'PERF-NETWORK-TCP-THROUGHPUT-MULTICONNECTION-NTTTCP-Synthetic,PERF-NETWORK-TCP-THROUGHPUT-MULTICONNECTION-NTTTCP-SRIOV' -ResultDBTable 'Perf_Network_TCP_Azure_DefaultKernel'",
    PERF_UDP:"-TestNames 'PERF-NETWORK-UDP-1K-THROUGHPUT-MULTICONNECTION-NTTTCP-Synthetic,PERF-NETWORK-UDP-1K-THROUGHPUT-MULTICONNECTION-NTTTCP-SRIOV' -ResultDBTable 'Perf_Network_UDP_Azure_DefaultKernel'",
    PERF_SINGLE_IPERF:"-TestNames 'PERF-NETWORK-TCP-SINGLE-CONNECTION-THROUGHPUT-SYNTHETIC,PERF-NETWORK-TCP-SINGLE-CONNECTION-THROUGHPUT-SRIOV' -ResultDBTable 'Perf_Network_Single_TCP_Azure_DefaultKernel'",
    PERF_LATENCY:"-TestNames 'PERF-NETWORK-TCP-LATENCY-Synthetic,PERF-NETWORK-TCP-LATENCY-SRIOV' -ResultDBTable 'Perf_Network_Latency_Azure_DefaultKernel'",
    PERF_STORAGE_4K:"-TestNames 'PERF-STORAGE-4K-IO' -StorageAccount 'ExistingStorage_Premium' -ResultDBTable 'Perf_Storage_Azure_DefaultKernel'"]
LATEST_VERSION_LOCATION="/home/lisa/latest_versions.sh"
PLATFORM_HYPERV = "hyperv"
PLATFORM_AZURE = "azure"
PLATFORM_ALL = "all"
LABEL_SRIOV = "sriov_mlnx"
LABEL_WS2016 = "ubuntu_azure_kernel_validation"
LISAV2_REMOTE = "https://github.com/lis/LISAv2.git"
LISAV2_BRANCH = "master"
AZURE_LOCATION_DEFAULT = "westus2"
AZURE_LOCATION_NVME = "eastus2"
AZURE_ID = "ubuntuAz"

def ARM_DISTRO = ARM_DISTRO_HASH.find{it.key == env.distro}.value
def HYPERV_VHD = HYPERV_VHD_HASH.find{it.key == env.distro}.value

if (env.KernelType == "linux-azure") {
    env.KERNEL_TYPE = "proposed-azure"
}
if (env.KernelType == "linux-azure-edge"){
    env.KERNEL_TYPE = "proposed-edge"
}

env.START_DATE = new java.sql.Timestamp(new Date().getTime())
env.END_DATE = ""
env.SIGNED_OFF_BY = ""
env.SIGNED_OFF_RESULT = ""

stage ("report_status_init") {
    node ("meta_slave") {
        checkout scm
        try {
            reportPipelineStatus("start")
        } catch (exc) {
            println exc
        }
    }
}

if ((env.platform == PLATFORM_ALL) || (env.platform == PLATFORM_AZURE)) {
    stage ("Azure-Validation-${env.distro}-${env.KernelType}") {
        def runs = [:]
        AZURE_VALIDATION_TESTS_HASH.each() {
            def test_type = it.key
            def test_cmd = it.value
            runs["${test_type}"] = {
                stage ("${test_type}") {
                    def AZURE_LOCATION = ""
                    if (test_cmd.contains("-TestArea 'NVME'")){
                        AZURE_LOCATION = AZURE_LOCATION_NVME
                    } else {
                        AZURE_LOCATION = AZURE_LOCATION_DEFAULT
                    }
                    node ("azure") {
                        try {
                            timeout (time: 48, unit: 'HOURS')  {
                                withCredentials(bindings: [
                                file(credentialsId:'Azure_Secrets_TESTONLY_File', variable: 'Azure_Secrets_File')]) {
                                    dir ("${distro}-${env.BUILD_NUMBER}-${env.BRANCH_NAME}") {
                                        cleanWs()
                                        git branch: LISAV2_BRANCH, url: LISAV2_REMOTE

                                        def stageInfo = [:]
                                        stageInfo["Name"] = "Azure-Validation-${env.distro}-${env.KernelType}-${test_type}"
                                        stageInfo["StartDate"] = new java.sql.Timestamp(new Date().getTime()).toString()
                                        stageInfo["EndDate"] = ''
                                        stageInfo["Platform"] = "Azure"
                                        try {
                                            lock ('db_reporting') {
                                                reportStageStatus(stageInfo, false)
                                            }
                                        } catch (exc) {
                                            println exc
                                        }

                                        echo "Run-LisaV2.ps1 -TestPlatform 'Azure' -ARMImageName '${ARM_DISTRO}' -RGIdentifier '${AZURE_ID}' -TestLocation '${AZURE_LOCATION}' -CustomKernel '${KERNEL_TYPE}' ${test_cmd} -XMLSecretFile '${Azure_Secrets_File}'"
                                        RunPowershellCommand(".\\Run-LisaV2.ps1" +
                                            " -TestLocation '${AZURE_LOCATION}'" +
                                            " -RGIdentifier '${AZURE_ID}'" +
                                            " -TestPlatform 'Azure'" +
                                            " -CustomKernel '${KERNEL_TYPE}'" +
                                            " -ARMImageName '${ARM_DISTRO}'" +
                                            " -XMLSecretFile '${Azure_Secrets_File}'" +
                                            " -EnableTelemetry" +
                                            " -ExitWithZero" +
                                            " ${test_cmd}"
                                        )
                                        archiveArtifacts artifacts: '*-TestLogs.zip', allowEmptyArchive: true
                                        junit testResults: "Report\\*-junit.xml", allowEmptyResults: true

                                        stageInfo["EndDate"] = new java.sql.Timestamp(new Date().getTime()).toString()
                                        try {
                                            lock ('db_reporting') {
                                                reportStageStatus(stageInfo, true)
                                            }
                                        } catch (exc) {
                                            println exc
                                        }
                                        deleteDir()
                                    }
                                }
                            }
                        } catch (exc) {
                            println exc
                            println "Azure-Validation-${test_type}: STAGE_FAILED_EXCEPTION."
                            currentBuild.result = 'SUCCESS'
                        }
                    }
                }
            }
        }
        parallel runs
    }
} else {
    echo "Skipping Azure validation"
}

if ((env.platform == PLATFORM_ALL) || (env.platform == PLATFORM_HYPERV)) {
    stage ("HyperV-Validation-${env.distro}-${env.KernelType}") {
        def runs = [:]
        HYPERV_VALIDATION_TESTS_HASH.each() {
            def test_type = it.key
            def test_cmd = it.value
            runs["${test_type}"] = {
                stage ("${test_type}") {
                    if (test_cmd.contains("TestArea 'SRIOV'")){
                        LABEL_NAME = LABEL_SRIOV
                    } else {
                        LABEL_NAME = LABEL_WS2016
                    }
                    node ("${LABEL_NAME}") {
                        try {
                            timeout (time: 24, unit: 'HOURS')  {
                                withCredentials(bindings: [
                                string(credentialsId:'SRIOV_TEST_LOCATION', variable: 'SRIOV_TEST_LOCATION'),
                                string(credentialsId:'LISAV2_IMAGES_SHARE_URL', variable: 'LISAV2_IMAGES_SHARE_URL'),
                                file(credentialsId:'HYPERV_LISAV2_SECRETS', variable: 'HYPERV_LISAV2_SECRETS')]) {
                                    dir ("${test_type}-${env.BUILD_NUMBER}-${env.BRANCH_NAME}") {
                                        cleanWs()
                                        git branch: LISAV2_BRANCH, url: LISAV2_REMOTE
                                        if (test_cmd.contains("TestArea 'SRIOV'")){
                                            test_location = "${SRIOV_TEST_LOCATION}"
                                        } else {
                                            test_location = "localhost"
                                        }
                                        HYPERV_VHD_PATH = "${LISAV2_IMAGES_SHARE_URL}${HYPERV_VHD}"

                                        def stageInfo = [:]
                                        stageInfo["Name"] = "HyperV-Validation-${env.distro}-${env.KernelType}-${test_type}"
                                        stageInfo["StartDate"] = new java.sql.Timestamp(new Date().getTime()).toString()
                                        stageInfo["EndDate"] = ''
                                        stageInfo["Platform"] = "HyperV"
                                        try {
                                            
                                            lock ('db_reporting') {
                                                reportStageStatus(stageInfo, false)
                                            }
                                        } catch (exc) {
                                            println exc
                                        }

                                        echo "Run-LisaV2.ps1 -TestPlatform 'HyperV' -OsVHD ${HYPERV_VHD_PATH} -RgIdentifier 'ubuntuAzure${distro}' -TestLocation '${test_location}' -CustomKernel '${KERNEL_TYPE}' ${test_cmd} -XMLSecretFile '${HYPERV_LISAV2_SECRETS}'"
                                        RunPowershellCommand(".\\Run-LisaV2.ps1" +
                                            " -TestLocation '${test_location}'" +
                                            " -RGIdentifier 'ubuntuAzure${distro}'" +
                                            " -TestPlatform 'HyperV'" +
                                            " -CustomKernel '${KERNEL_TYPE}'" +
                                            " -OsVHD '${HYPERV_VHD_PATH}'" +
                                            " -XMLSecretFile '${HYPERV_LISAV2_SECRETS}'" +
                                            " -EnableTelemetry" +
                                            " -ExitWithZero" +
                                            " ${test_cmd}"
                                        )
                                        archiveArtifacts artifacts: '*-TestLogs.zip', allowEmptyArchive: true
                                        junit testResults: "Report\\*-junit.xml", allowEmptyResults: true

                                        stageInfo["EndDate"] = new java.sql.Timestamp(new Date().getTime()).toString()
                                        try {
                                            lock ('db_reporting') {
                                                reportStageStatus(stageInfo, true)
                                            }
                                        } catch (exc) {
                                            println exc
                                        }
                                        deleteDir()
                                    }
                                }
                            }
                        } catch (exc) {
                            println exc
                            println "HyperV-Validation-${test_type}: STAGE_FAILED_EXCEPTION."
                            currentBuild.result = 'SUCCESS'
                        }
                    }
                }
            }
        }
        parallel runs
    }
} else {
    echo "Skipping Hyper-V validation"
}

if (env.performance == "yes") {
    stage ("Performance-${env.distro}-${env.KernelType}") {
        def runs = [:]
        AZURE_PERFORMANCE_TESTS_HASH.each() {
            def test_type = it.key
            def test_cmd = it.value
            runs["${test_type}"] = {
                stage ("${test_type}") {
                    node ("azure"){
                        try {
                            timeout (time: 12, unit: 'HOURS')  {
                                withCredentials(bindings: [
                                file(credentialsId:'Azure_Secrets_TESTONLY_File', variable: 'Azure_Secrets_File')]) {
                                    dir ("${distro}-${env.BUILD_NUMBER}-${env.BRANCH_NAME}") {
                                        cleanWs()
                                        git branch: LISAV2_BRANCH, url: LISAV2_REMOTE

                                        def stageInfo = [:]
                                        stageInfo["Name"] = "Performance-Validation-${env.distro}-${env.KernelType}-${test_type}"
                                        stageInfo["StartDate"] = new java.sql.Timestamp(new Date().getTime()).toString()
                                        stageInfo["EndDate"] = ''
                                        stageInfo["Platform"] = "Azure"
                                        try {
                                            lock ('db_reporting') {
                                                reportStageStatus(stageInfo, false)
                                            }
                                        } catch (exc) {
                                            println exc
                                        }

                                        echo "Run-LisaV2.ps1 -TestPlatform 'Azure' -ARMImageName '${ARM_DISTRO}' -RGIdentifier '${AZURE_ID}' -TestLocation '${AZURE_LOCATION_DEFAULT}' -CustomKernel '${KERNEL_TYPE}' ${test_cmd} -XMLSecretFile '${Azure_Secrets_File}'"
                                        RunPowershellCommand(".\\Run-LisaV2.ps1" +
                                            " -TestLocation '${AZURE_LOCATION_DEFAULT}'" +
                                            " -RGIdentifier '${AZURE_ID}'" +
                                            " -TestPlatform 'Azure'" +
                                            " -CustomKernel '${KERNEL_TYPE}'" +
                                            " -ARMImageName '${ARM_DISTRO}'" +
                                            " -XMLSecretFile '${Azure_Secrets_File}'" +
                                            " -EnableTelemetry" +
                                            " -ExitWithZero" +
                                            " -ResultDBTestTag '${env.distro}_${env.KernelType}_${env.BUILD_NUMBER}'" +
                                            " ${test_cmd}"
                                        )
                                        archiveArtifacts artifacts: '*-TestLogs.zip', allowEmptyArchive: true
                                        junit testResults: "Report\\*-junit.xml", allowEmptyResults: true

                                        stageInfo["EndDate"] = new java.sql.Timestamp(new Date().getTime()).toString()
                                        try {
                                            lock ('db_reporting') {
                                                reportStageStatus(stageInfo, true)
                                            }
                                        } catch (exc) {
                                            println exc
                                        }
                                        deleteDir()
                                    }
                                }
                            }
                        } catch (exc) {
                            println exc
                            println "Azure-${test_type}: STAGE_FAILED_EXCEPTION."
                            currentBuild.result = 'SUCCESS'
                        }
                    }
                }
            }
        }
        parallel runs
    }
} else {
    echo "Skipping Azure Performance"
}

if (env.sendMail == "yes"){
    node ("meta_slave") {
        echo "Send email with kernel validation results link"
        if (env.KernelType == "linux-azure") {
            version_identifier = "_azure"
        } else {
            version_identifier = "_edge"
        }
        try {
            kernels_info = readFile (LATEST_VERSION_LOCATION)
        } catch (exc) {
            echo "${LATEST_VERSION_LOCATION} could not be found on the server!"
            return
        }
        kernels_info = kernels_info.split("\n")
        kernels_info.each {
            if (it.contains("${env.distro}${version_identifier}")) {
                latest_kernel_version = it.split("=")[1]
            }
        }
        stage('Send-email') {
            withCredentials([string(credentialsId: 'MAIL_LIST_OWNER', variable: 'MAIL_LIST_OWNER')]) {
                emailext (
                    subject: "Please sign off ${latest_kernel_version} ${env.KernelType} kernel for ${env.distro}",
                    to: "${env.MAIL_LIST_OWNER}",
                    mimeType : "text/html",
                    body: '${SCRIPT, template="ubuntu.template"}'
                )
            }
        }
        stage('Kernel-Sign-Off') {
            def owner
            withCredentials([string(credentialsId: 'MAIL_LIST_SIGNOFF', variable: 'MAIL_LIST_SIGNOFF')]) {
                try {
                    checkout scm
                    echo "Ask for manual sign-off from the owner"
                    timeout(time: 72, unit: 'HOURS') {
                        signoff = input(message: "Are you sure you want to sign off ${env.distro} ${latest_kernel_version} ${env.KernelType} kernel?",
                            parameters: [string(defaultValue: 'Press Proceed/Abort after verifying the test results', description: '', name: '')],
                            submitterParameter: "USER")
                        owner = signoff["USER"]
                    }
                    env.SIGNED_OFF_BY = owner
                    env.SIGNED_OFF_RESULT = "true"
                    emailext (
                        subject: "${latest_kernel_version} ${env.KernelType} kernel for ${env.distro} can be signed off. ${owner}",
                        to:"${env.MAIL_LIST_SIGNOFF}",
                        mimeType : "text/html",
                        body: """
                            Hello,<br/><br/>
                            ${latest_kernel_version} ${env.KernelType} kernel for ${env.distro} is OK and was signed off by ${owner}<br/>
                            URL: ${env.BUILD_URL}<br/><br/>
                            Thank you,<br/>Jenkins CI
                        """
                    )
                } catch (exc) {
                    owner = exc.getCauses()[0].getUser()
                    env.SIGNED_OFF_BY = owner
                    env.SIGNED_OFF_RESULT = "false"
                    emailext (
                        subject: "${latest_kernel_version} ${env.KernelType} kernel for ${env.distro} can't be signed off. ${owner}",
                        to: "${env.MAIL_LIST_SIGNOFF}",
                        mimeType : "text/html",
                        body: """
                            Hello,<br/><br/>
                            ${latest_kernel_version} ${env.KernelType} kernel for ${env.distro} is not good/was not signed off in time - ${owner}<br/>
                            URL: ${env.BUILD_URL}<br/><br/>
                            Thank you,<br/>Jenkins CI
                        """
                    )
                }
            }
        }
    }
}

stage ("report_status_end") {
    node ("meta_slave") {
        checkout scm
        env.END_DATE = new java.sql.Timestamp(new Date().getTime())
        try {
            reportPipelineStatus("finish")
        } catch (exc) {
            println exc
        }
    }
}
